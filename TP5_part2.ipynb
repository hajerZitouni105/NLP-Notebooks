{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg6I6av2mMyP",
        "outputId": "c863d9b4-7470-4eb0-b244-2783938f75dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('punkt')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xreO1poRm1OS"
      },
      "source": [
        "1. Charger le corpus twitter_samples dans une liste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyapbgiumsFT"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "tweets = twitter_samples.strings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF6QbcB0nH0B"
      },
      "source": [
        "2. Définir une fonction est_positif() qui utilise un modèle d'analyse des sentiments prédéfini pour déterminer si un tweet est positif ou non :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4IyUZeRmsCm"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def est_positif(tweet):\n",
        "    sia = SentimentIntensityAnalyzer()  #Création d'une instance de SentimentIntensityAnalyzer() :\n",
        "    sentiment_score = sia.polarity_scores(tweet)['compound']   #Calcul du score de sentiment à l'aide de polarity_scores() et récupération du score \"compound\" :\n",
        "    return sentiment_score > 0    #Renvoi d'une valeur booléenne indiquant si le sentiment est positif ou non :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9nJVKY7n2V9"
      },
      "source": [
        "\"compound\" est une valeur numérique comprise entre -1 et +1 qui représente la positivité ou la négativité globale du texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm8NAdK6oyrD"
      },
      "source": [
        "3.Examinons maintenant le second corpus, movie_reviews, qui a déjà été classé. Créez une liste\n",
        "des ID des avis utilisés par le corpus, que vous pourrez utiliser plus tard pour référencer des\n",
        "révisions individuelles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUHswxgemsAY"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "# Obtention de la liste des ID des avis\n",
        "review_ids = movie_reviews.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsZ8Diqgmr-O",
        "outputId": "099f8891-e26f-47f5-d7be-e790aa29d45a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['neg/cv000_29416.txt',\n",
              " 'neg/cv001_19502.txt',\n",
              " 'neg/cv002_17424.txt',\n",
              " 'neg/cv003_12683.txt',\n",
              " 'neg/cv004_12641.txt',\n",
              " 'neg/cv005_29357.txt',\n",
              " 'neg/cv006_17022.txt',\n",
              " 'neg/cv007_4992.txt',\n",
              " 'neg/cv008_29326.txt',\n",
              " 'neg/cv009_29417.txt']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Affichage des premiers 10 ID pour vérification\n",
        "review_ids[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kLZmWZ8mr5b"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def est_positif(review_id):\n",
        "    # Créer une instance de SentimentIntensityAnalyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Récupérer le texte de l'avis à partir de son ID\n",
        "    review_text = movie_reviews.raw(review_id)\n",
        "\n",
        "    # Diviser le texte en phrases\n",
        "    sentences = sent_tokenize(review_text)\n",
        "\n",
        "    # Initialiser le score de sentiment total\n",
        "    total_sentiment_score = 0\n",
        "\n",
        "    # Calculer le score de sentiment pour chaque phrase et l'ajouter au score total\n",
        "    for sentence in sentences:\n",
        "        sentiment_score = sia.polarity_scores(sentence)['compound']\n",
        "        total_sentiment_score += sentiment_score\n",
        "\n",
        "    # Calculer le score moyen de sentiment pour l'avis entier\n",
        "    average_sentiment_score = total_sentiment_score / len(sentences)\n",
        "\n",
        "    # Retourner True si le score moyen est positif, sinon False\n",
        "    return average_sentiment_score > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtZPCRFFmr25",
        "outputId": "1b201c70-7e64-4aa1-b053-8c5c6a46c2ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Précision du modèle prédéfini : 64.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Obtenir la liste des ID des avis\n",
        "review_ids = movie_reviews.fileids()\n",
        "\n",
        "# Initialiser les compteurs pour le nombre de prédictions correctes\n",
        "correct_predictions = 0\n",
        "\n",
        "# Parcourir tous les avis et évaluer les prédictions\n",
        "for review_id in review_ids:\n",
        "    # Déterminer si l'avis est positif ou non\n",
        "    prediction = est_positif(review_id)\n",
        "\n",
        "    # Récupérer l'étiquette réelle de l'avis (pos ou neg)\n",
        "    actual_label = review_id.split('/')[0]\n",
        "\n",
        "    # Vérifier si la prédiction est correcte en comparant avec l'étiquette réelle\n",
        "    if (prediction and actual_label == 'pos') or (not prediction and actual_label == 'neg'):\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Calculer la précision en pourcentage\n",
        "accuracy = (correct_predictions / len(review_ids)) * 100\n",
        "\n",
        "# Afficher la précision\n",
        "print(\"Précision du modèle prédéfini : {:.2f}%\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kQWPxjBmr0q",
        "outputId": "6e54bd4f-0bd4-4214-c7e5-b575d96d3912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Précision du modèle TextBlob : 60.0 %\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Chargement du corpus movie_reviews\n",
        "review_ids = movie_reviews.fileids()\n",
        "\n",
        "# Fonction pour évaluer le sentiment avec TextBlob\n",
        "def est_positif_textblob(review_id):\n",
        "    review_text = movie_reviews.raw(review_id)\n",
        "    blob = TextBlob(review_text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    return sentiment_score > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BVTriLD87Qcz",
        "outputId": "ee7a6b7d-a4fe-4d1e-d682-e9f1cdb8db34"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'review_ids' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f480ebfa950a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Évaluation de tous les avis et calcul de la précision du modèle TextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcorrect_predictions_textblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mreview_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest_positif_textblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mactual_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'review_ids' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# 6. Réexécution du travail avec un autre modèle prédéfini (par exemple, TextBlob)\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Définition de la fonction est_positif_textblob() pour les avis de films\n",
        "def est_positif_textblob(review_id):\n",
        "    review_text = movie_reviews.raw(review_id)\n",
        "    blob = TextBlob(review_text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    return sentiment_score > 0\n",
        "\n",
        "# Évaluation de tous les avis et calcul de la précision du modèle TextBlob\n",
        "correct_predictions_textblob = 0\n",
        "for review_id in review_ids:\n",
        "    prediction = est_positif_textblob(review_id)\n",
        "    actual_label = review_id.split('/')[0]\n",
        "    if (prediction and actual_label == 'pos') or (not prediction and actual_label == 'neg'):\n",
        "        correct_predictions_textblob += 1\n",
        "accuracy_textblob = (correct_predictions_textblob / total_reviews) * 100\n",
        "print(\"Précision du modèle TextBlob :\", accuracy_textblob, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY4KDrGbx67F"
      },
      "source": [
        "Ces résultats indiquent que le modèle prédéfini a une légère amélioration de la précision par rapport à TextBlob dans la tâche spécifique d'analyse de sentiment des avis de films du corpus movie_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6zBQSqdyisP"
      },
      "source": [
        "Exercice 2 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkbtyDwzx8rF"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk import FreqDist, pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 1. Création des lexiques positifs et négatifs et étiquetage morpho-syntaxique\n",
        "positive_words = []\n",
        "negative_words = []\n",
        "\n",
        "for fileid in movie_reviews.fileids():\n",
        "    words = movie_reviews.words(fileid)\n",
        "    if fileid.startswith('pos'):\n",
        "        positive_words.extend(words)\n",
        "    else:\n",
        "        negative_words.extend(words)\n",
        "# Étiquetage morpho-syntaxique des mots dans les lexiques\n",
        "positive_words_tagged = pos_tag(positive_words)\n",
        "negative_words_tagged = pos_tag(negative_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcdiW_yqx8ni"
      },
      "outputs": [],
      "source": [
        "# 2. Création des distributions de fréquence pour l'attribut personnalisé\n",
        "positive_freq_dist = FreqDist(positive_words)\n",
        "negative_freq_dist = FreqDist(negative_words)\n",
        "# Suppression des mots présents dans les deux ensembles pour éviter les doublons\n",
        "common_words = set(positive_words).intersection(set(negative_words))\n",
        "for word in common_words:\n",
        "    del positive_freq_dist[word]\n",
        "    del negative_freq_dist[word]\n",
        "\n",
        "# Sélection des 100 mots les plus courants dans chaque distribution\n",
        "top_positive_words = positive_freq_dist.most_common(100)\n",
        "top_negative_words = negative_freq_dist.most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H7CCtYnx8c1"
      },
      "outputs": [],
      "source": [
        "# 3. Extraction des collocations\n",
        "collocations = []\n",
        "\n",
        "for fileid in movie_reviews.fileids():\n",
        "    words = movie_reviews.words(fileid)\n",
        "    collocations.extend(nltk.bigrams(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ybj_mkk3zKWR"
      },
      "outputs": [],
      "source": [
        "# 4. Définition de la fonction extraire_attributs()\n",
        "def extraire_attributs(texte):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    compound_score = sia.polarity_scores(texte)['compound']\n",
        "    positive_score = sia.polarity_scores(texte)['pos']\n",
        "    tokens = word_tokenize(texte)\n",
        "    common_positive_words = sum(1 for word in tokens if word in [word[0] for word in top_positive_words])\n",
        "\n",
        "    return {\n",
        "        'compound_score': compound_score + 1,  # Ajout de 1 pour rendre les scores toujours positifs\n",
        "        'positive_score': positive_score,\n",
        "        'common_positive_words': common_positive_words\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFHeAUFRzKS2"
      },
      "outputs": [],
      "source": [
        "# 5. Création d'une liste d'attributs pour chaque avis\n",
        "attributs_avis = []\n",
        "for fileid in movie_reviews.fileids():\n",
        "    texte = ' '.join(movie_reviews.words(fileid))\n",
        "    attributs = extraire_attributs(texte)\n",
        "    if fileid.startswith('pos'):\n",
        "        attributs_avis.append((attributs, 'positif'))\n",
        "    else:\n",
        "        attributs_avis.append((attributs, 'négatif'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrYRApV_zTFc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Test de l'apprentissage et de l'évaluation des nouveaux attributs avec différents classifieurs\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train, test = train_test_split(attributs_avis, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entraînement du classifieur Naive Bayes\n",
        "classifieur = NaiveBayesClassifier.train(train)\n",
        "\n",
        "# Prédiction sur l'ensemble de test\n",
        "predictions = [classifieur.classify(attr) for (attr, label) in test]\n",
        "\n",
        "# Calcul de la précision\n",
        "precision = accuracy_score([label for (attr, label) in test], predictions)\n",
        "print(\"Précision du classifieur Naive Bayes:\", precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfnA9pRIYh-q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Chargement du jeu de données D_Finance.csv\n",
        "data = pd.read_csv(\"D_Finance.csv\")\n",
        "\n",
        "# Affichage des premières lignes du jeu de données\n",
        "print(data.head())\n",
        "\n",
        "# 2. Prétraitement : Tokenisation et vectorisation des phrases avec CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(data['sentence']) # 'sentence' est le nom de la colonne contenant les phrases\n",
        "y = data['label'] # 'label' est le nom de la colonne contenant les étiquettes\n",
        "\n",
        "# 3. Division des données en apprentissage et test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# 4. Apprentissage du modèle (à compléter selon l'algorithme de classification choisi)\n",
        "# Par exemple, avec un classifieur Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Création du classifieur Naive Bayes\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Entraînement du classifieur sur les données d'apprentissage\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5. Évaluation du modèle\n",
        "# Prédiction sur les données de test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Évaluation de la précision du modèle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Précision du modèle:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzugDS4mx8M6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}