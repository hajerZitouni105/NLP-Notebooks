{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bBAt94qBKrn4"
      },
      "outputs": [],
      "source": [
        "import wave\n",
        "import speech_recognition as sr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1)"
      ],
      "metadata": {
        "id": "sWZm6VHCK2oc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb7XrAHiKrn6",
        "outputId": "b70167ac-b7ac-4bc1-e54a-eea8e6a1d49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of channels: 1\n",
            "Sample width (in bytes): 2\n",
            "Frame rate (samples per second): 16000\n",
            "Number of frames: 46400\n"
          ]
        }
      ],
      "source": [
        "with wave.open(\"exemple_1.wav\", 'rb') as wav_file:\n",
        "    num_channels = wav_file.getnchannels()\n",
        "    sample_width = wav_file.getsampwidth()\n",
        "    frame_rate = wav_file.getframerate()\n",
        "    num_frames = wav_file.getnframes()\n",
        "\n",
        "    print(f\"Number of channels: {num_channels}\")\n",
        "    print(f\"Sample width (in bytes): {sample_width}\")\n",
        "    print(f\"Frame rate (samples per second): {frame_rate}\")\n",
        "    print(f\"Number of frames: {num_frames}\")\n",
        "\n",
        "    audio_data = wav_file.readframes(num_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2)"
      ],
      "metadata": {
        "id": "ckrAV8mKK8gG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0We4REf8Krn8",
        "outputId": "eb751f97-8365-4068-fb68-b57cd7d8d467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text from speech:  I believe you are just talking nonsense\n"
          ]
        }
      ],
      "source": [
        "recognizer = sr.Recognizer()\n",
        "with sr.AudioFile(\"exemple_1.wav\") as audio_file:\n",
        "\n",
        "    audio_data = recognizer.record(audio_file)\n",
        "\n",
        "    try:\n",
        "        text_result = recognizer.recognize_google(audio_data)\n",
        "        print(\"Text from speech: \", text_result)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Web Speech API could not understand the audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Error with the Google Web Speech API request; {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3)"
      ],
      "metadata": {
        "id": "oPCGEz1-Lld_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr #reconnaissance vocale\n",
        "import os\n",
        "from pydub import AudioSegment #manipulation d'audio\n",
        "from pydub.silence import split_on_silence #manipulation d'audio\n",
        "\n",
        "r = sr.Recognizer() #Initialisation du Recognizer\n",
        "\n",
        "def transcription_grand_audio(path): #prend en param√®tre le chemin du fichier audio\n",
        "    sound = AudioSegment.from_wav(path)#load the audio file\n",
        "\n",
        "    #split the audio on silences\n",
        "    chunks = split_on_silence(sound,\n",
        "                              min_silence_len=500,\n",
        "                              silence_thresh=sound.dBFS-14,\n",
        "                              keep_silence=500)\n",
        "\n",
        "    #create a folder \"chunks\" to store the audio chunks\n",
        "    folder_name = \"chunks\"\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "\n",
        "    #initialize variable 'whole_text' to store the transcription\n",
        "    whole_text = \"\"\n",
        "\n",
        "    #boucle sur chaque morceau pour la transcription\n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        #export the audio chunk as a vaw file into 'chunks' folder\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "        #recognize speech in the audio chunk using google web speech API\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "\n",
        "        try:\n",
        "            #attempt to recognize the speech in the audio chunk\n",
        "            text = r.recognize_google(audio_listened)\n",
        "        except sr.UnknownValueError as e:\n",
        "            #handle cases where speech cannot be recognized\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            #capitalize the recognized text and print the result\n",
        "            text = f\"{text.capitalize()}.\"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            #append the recognized text to the complete transcription\n",
        "            whole_text += text\n",
        "\n",
        "    #return the complete transcription\n",
        "    return whole_text\n"
      ],
      "metadata": {
        "id": "-4QzWTBwcCXT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription_grand_audio(\"grand_audio.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "7h4-dBreecls",
        "outputId": "b75030df-ac5b-46a7-d942-f7d3f509e581"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunks/chunk1.wav : Here's a bird which he had fixed in a bowery or a country seat.\n",
            "chunks/chunk2.wav : Add a short distance from the city.\n",
            "chunks/chunk3.wav : Just that what is now called dutch street.\n",
            "chunks/chunk4.wav : Soon abounded with proofs of his ingenuity.\n",
            "chunks/chunk5.wav : Patent smoke.\n",
            "chunks/chunk6.wav : It required a horse to work some.\n",
            "chunks/chunk7.wav : Dutch ovens that roasted meat without fire.\n",
            "chunks/chunk8.wav : Carts that went before the horses.\n",
            "chunks/chunk9.wav : Weather cox that turned against the wind and other wrong-headed contrivances.\n",
            "chunks/chunk10.wav : Set astonished and confounded all beholders.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here's a bird which he had fixed in a bowery or a country seat.Add a short distance from the city.Just that what is now called dutch street.Soon abounded with proofs of his ingenuity.Patent smoke.It required a horse to work some.Dutch ovens that roasted meat without fire.Carts that went before the horses.Weather cox that turned against the wind and other wrong-headed contrivances.Set astonished and confounded all beholders.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4)"
      ],
      "metadata": {
        "id": "O15oigXAeXvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_speech(duration=5):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.Microphone() as source:\n",
        "        print(f\"Listening for {duration} seconds...\")\n",
        "\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "\n",
        "        audio_data = recognizer.listen(source, timeout=duration)\n",
        "\n",
        "        print(\"Recording complete.\")\n",
        "\n",
        "    try:\n",
        "        text_result = recognizer.recognize_google(audio_data)\n",
        "        print(\"Speech captured:\", text_result)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Google Web Speech API could not understand the audio\")\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Error with the Google Web Speech API request; {e}\")\n"
      ],
      "metadata": {
        "id": "5EJMKtJfeYnU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5)"
      ],
      "metadata": {
        "id": "nEhxgB8VhEdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "capture_speech(duration=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "u04QhuPbhGXI",
        "outputId": "8eb61684-b951-4dd8-915c-b60420c56ce3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No Default Input Device Available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1b2ed5af5550>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcapture_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-8331c6977fc3>\u001b[0m in \u001b[0;36mcapture_speech\u001b[0;34m(duration)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrecognizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Listening for {duration} seconds...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Device index out of range ({} devices available; device index should be between 0 and {} inclusive)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# automatically set the sample rate to the hardware's default sample rate if not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mdevice_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_info_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_input_device_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Invalid device info returned from PyAudio: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"defaultSampleRate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36mget_default_input_device_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \"\"\"\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_input_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_info_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No Default Input Device Available"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}